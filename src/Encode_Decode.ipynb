{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from data_scripts.LevelDataset import LevelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Tensor(\"Cast:0\", shape=(None, None, None), dtype=float32)\n",
      "*****Dataset:**** <_MapDataset element_spec=(TensorSpec(shape=(None, None, None), dtype=tf.float32, name=None), {'block_amount': TensorSpec(shape=(), dtype=tf.int64, name=None), 'level_height': TensorSpec(shape=(), dtype=tf.float32, name=None), 'level_width': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pig_amount': TensorSpec(shape=(), dtype=tf.int64, name=None), 'pixel_height': TensorSpec(shape=(), dtype=tf.int64, name=None), 'pixel_width': TensorSpec(shape=(), dtype=tf.int64, name=None), 'platform_amount': TensorSpec(shape=(), dtype=tf.int64, name=None), 'special_block_amount': TensorSpec(shape=(), dtype=tf.int64, name=None)})>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_datasets/test_run_200/test_run_200.tfrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m LevelDataset(dataset_path \u001b[38;5;241m=\u001b[39m dataset_path, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m iter_data \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[1;32mf:\\AI in games\\Final\\Resources\\Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds\\src\\data_scripts\\LevelDataset.py:43\u001b[0m, in \u001b[0;36mLevelDataset.load_dataset\u001b[1;34m(self, normalize)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*****Dataset:****\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_steps()\n",
      "File \u001b[1;32mf:\\AI in games\\Final\\Resources\\Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds\\src\\data_scripts\\LevelDataset.py:47\u001b[0m, in \u001b[0;36mLevelDataset.normalize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_element \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(images)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_layer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_element \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mf:\\AI in games\\Final\\Resources\\Utilizing-Generative-Adversarial-Networks-for-Stable-Structure-Generation-in-Angry-Birds\\src\\data_scripts\\LevelDataset.py:47\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_element \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(images)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_layer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_element \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    808\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 772\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3081\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3080\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3081\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3082\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3083\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3085\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_path = \"train_datasets/test_run_200/test_run_200.tfrecords\"\n",
    "dataset = LevelDataset(dataset_path = dataset_path, batch_size = 1)\n",
    "dataset.load_dataset()\n",
    "iter_data = dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 5)\n",
      "dict_keys(['block_amount', 'level_height', 'level_width', 'pig_amount', 'pixel_height', 'pixel_width', 'platform_amount', 'special_block_amount'])\n"
     ]
    }
   ],
   "source": [
    "for image_batch, data in iter_data:\n",
    "    # print(data)\n",
    "    print(image_batch.shape)\n",
    "    print(data.keys())\n",
    "    original = image_batch[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (1.26.3)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (PEP 517): started\n",
      "  Building wheel for gym (PEP 517): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827634 sha256=9ce6f79e6182d075041bbbbfc8883fd27d6bb4162e28acfd03990367066f244e\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\b9\\22\\6d\\3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-3.0.0 gym-0.26.2 gym-notices-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom environment\n",
    "class Environment:\n",
    "    def init(self, map, max_step=math.inf):\n",
    "        self.map = map\n",
    "        self.state = copy.deepcopy(map)\n",
    "        self.step_count = 0\n",
    "        self.max_step = max_step\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = copy.deepcopy(self.map)\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "\n",
    "        state_tensor = torch.tensor(self.state)\n",
    "        return state_tensor\n",
    "\n",
    "    def step(self, action, distance):\n",
    "        # add that pixel to the state (level map)\n",
    "        # action[0] is the x coordinate, action[1] is the y coordinate, action[2] is the type\n",
    "        self.state[action[0], action[1], action[2]] = 1\n",
    "        self.step_count += 1\n",
    "        # reward = self.reward_func(action[0], action[1], action[2], distance)\n",
    "        reward = 0\n",
    "\n",
    "        if self.step_count > self.max_step:\n",
    "            self.done = True\n",
    "\n",
    "        info = {'step': self.step_count, 'action': action, 'reward': reward, 'done': self.done}\n",
    "\n",
    "        return torch.tensor(self.state), torch.tensor(reward), self.done, info\n",
    "    \n",
    "    def reward_func(action, average_pixel):\n",
    "        # get the distance from average of the empty pixels\n",
    "        return 1/(1+math.sqrt((action[0] - average_pixel[0])**2 + (action[1] - average_pixel[1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Tensor(\"Cast:0\", shape=(None, None, None), dtype=float32)\n",
      "*****Dataset:**** <_MapDataset element_spec=(TensorSpec(shape=(None, None, None), dtype=tf.float32, name=None), {'block_amount': TensorSpec(shape=(), dtype=tf.int64, name=None), 'level_height': TensorSpec(shape=(), dtype=tf.float32, name=None), 'level_width': TensorSpec(shape=(), dtype=tf.float32, name=None), 'pig_amount': TensorSpec(shape=(), dtype=tf.int64, name=None), 'pixel_height': TensorSpec(shape=(), dtype=tf.int64, name=None), 'pixel_width': TensorSpec(shape=(), dtype=tf.int64, name=None), 'platform_amount': TensorSpec(shape=(), dtype=tf.int64, name=None), 'special_block_amount': TensorSpec(shape=(), dtype=tf.int64, name=None)})>\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"train_datasets/modified_test_run_200/modified_test_run_200.tfrecords\"\n",
    "modified_dataset = LevelDataset(dataset_path = dataset_path, batch_size = 1)\n",
    "modified_dataset.load_dataset()\n",
    "modified_iter_data = modified_dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 5)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, data in modified_iter_data:\n",
    "    # print(data)\n",
    "    print(image_batch.shape)\n",
    "    modified = image_batch[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_36200\\624638252.py:87: UserWarning: Using a target size (torch.Size([100, 100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = -torch.min(surr1, surr2) + torch.nn.functional.smooth_l1_loss(self.v(s), td_target.detach()) - 0.01 * entropy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Score: 560.0, Loss: -115.9814224243164\n",
      "Episode Score: 400.0, Loss: -115.5979995727539\n",
      "Episode Score: 320.0, Loss: 135.01531982421875\n",
      "Episode Score: -440.0, Loss: -115.64007568359375\n",
      "Episode Score: -800.0, Loss: 135.09259033203125\n",
      "Episode Score: -960.0, Loss: 135.3439178466797\n",
      "Episode Score: -1000.0, Loss: 135.3000946044922\n",
      "Episode Score: -1000.0, Loss: 134.88706970214844\n",
      "Episode Score: -1000.0, Loss: 134.1809844970703\n",
      "Episode Score: -1000.0, Loss: 133.35987854003906\n",
      "Episode Score: -1000.0, Loss: 132.32749938964844\n",
      "Episode Score: -1000.0, Loss: 131.28599548339844\n",
      "Episode Score: -1000.0, Loss: 129.75296020507812\n",
      "Episode Score: -1000.0, Loss: 128.5696563720703\n",
      "Episode Score: -1000.0, Loss: 126.82514953613281\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 119\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Assume modified_iter_data is your dataset\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_iter_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[80], line 106\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(modified_iter_data)\u001b[0m\n\u001b[0;32m    104\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m--> 106\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Policy forward pass\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     m \u001b[38;5;241m=\u001b[39m Categorical(prob)  \u001b[38;5;66;03m# Distribution for sampling actions\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     action_index \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# Sample an action\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[80], line 52\u001b[0m, in \u001b[0;36mPPO.pi\u001b[1;34m(self, x, softmax_dim)\u001b[0m\n\u001b[0;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_pi(x)\n\u001b[1;32m---> 52\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoftmax_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prob\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Define a custom environment\n",
    "class Environment:\n",
    "    def __init__(self, map, max_step=100):\n",
    "        self.map = map  # Initialize the map\n",
    "        self.state = copy.deepcopy(self.map)\n",
    "        self.step_count = 0\n",
    "        self.max_step = max_step\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = copy.deepcopy(self.map)\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "        state_tensor = torch.tensor(self.state, dtype=torch.float32).flatten()\n",
    "        return state_tensor\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y, z = action  # Decompose the action into coordinates\n",
    "        if self.state[x, y, z] == -1:\n",
    "            self.state[x, y, z] = 1  # Place block if the spot is empty\n",
    "            reward = 10  # Positive reward for placing a block\n",
    "        else:\n",
    "            reward = -10 # Negative reward if block is already there\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.max_step:\n",
    "            self.done = True\n",
    "        return torch.tensor(self.state, dtype=torch.float32).flatten(), reward, self.done, {}\n",
    "\n",
    "# PPO Model\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PPO, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc_pi = nn.Linear(128, input_size)\n",
    "        self.fc_v = nn.Linear(128, 1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.0003)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.99)\n",
    "        self.data = []  # Initialize data list for storing transitions\n",
    "\n",
    "    def pi(self, x, softmax_dim=0):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc_pi(x)\n",
    "        prob = torch.softmax(x, dim=softmax_dim)\n",
    "        return prob\n",
    "\n",
    "    def v(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "\n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "\n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = zip(*self.data)\n",
    "        self.data = []\n",
    "        return torch.stack(s_lst), torch.tensor(a_lst, dtype=torch.long), torch.tensor(r_lst, dtype=torch.float), torch.stack(s_prime_lst), torch.tensor(done_lst, dtype=torch.float)\n",
    "\n",
    "    def train_net(self, gamma=0.98, lmbda=0.95, eps_clip=0.2):\n",
    "        s, a, r, s_prime, done = self.make_batch()\n",
    "        td_target = r + gamma * self.v(s_prime) * (1 - done)\n",
    "        delta = td_target - self.v(s)\n",
    "        delta = delta.detach().numpy()\n",
    "        advantage_lst = []\n",
    "        advantage = 0.0\n",
    "        for delta_t in delta[::-1]:\n",
    "            advantage = gamma * lmbda * advantage + delta_t[0]\n",
    "            advantage_lst.append([advantage])\n",
    "        advantage_lst.reverse()\n",
    "        advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "        pi = self.pi(s, softmax_dim=1)\n",
    "        pi_a = pi.gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "        ratio = torch.exp(torch.log(pi_a) - torch.log(pi_a.detach()))\n",
    "        surr1 = ratio * advantage\n",
    "        surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantage\n",
    "        entropy = -(pi * torch.log(pi + 1e-5)).sum(1).mean()\n",
    "        loss = -torch.min(surr1, surr2) + torch.nn.functional.smooth_l1_loss(self.v(s), td_target.detach()) - 0.01 * entropy\n",
    "        self.optimizer.zero_grad()\n",
    "        loss_mean = loss.mean()  # Compute mean loss\n",
    "        loss_mean.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        return loss_mean  # Return the mean loss value\n",
    "\n",
    "def main(modified_iter_data):\n",
    "    model = PPO(128*128*5)  # Initialize the PPO model\n",
    "    score = 0.0\n",
    "    for image_batch, data in modified_iter_data:\n",
    "        \n",
    "        score = 0.0\n",
    "        env = Environment(image_batch[0].numpy())  # Create environment from batch\n",
    "        state = env.reset()  # Reset environment at the start of each batch\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            prob = model.pi(state)  # Policy forward pass\n",
    "            m = Categorical(prob)  # Distribution for sampling actions\n",
    "            action_index = m.sample().item()  # Sample an action\n",
    "            action = (action_index // (128*128), (action_index % (128*128)) // 128, action_index % 5)  # Decode action index to 3D action\n",
    "            state_prime, reward, done, _ = env.step(action)  # Execute action in the environment\n",
    "            model.put_data((state, action_index, reward, state_prime, done))  # Store data for training\n",
    "            state = state_prime\n",
    "            score += reward  # Update score\n",
    "        loss = model.train_net()  # Train model\n",
    "        print(f\"Episode Score: {score}, Loss: {loss}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Assume modified_iter_data is your dataset\n",
    "    main(modified_iter_data)\n",
    "    # Save the model\n",
    "    print(\"Model saved successfully\")\n",
    "    torch.save(model.state_dict(), 'ppo_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "print(\"Loading ...\")\n",
    "model = PPO(128*128*5)  # Recreate the model\n",
    "model.load_state_dict(torch.load('ppo_model.pth'))  # Load the saved parameters\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for image_batch, data in modified_iter_data:  # Assuming test data is provided in test_iter_data\n",
    "        state = env.reset()  # Reset the environment\n",
    "        done = False\n",
    "        while not done:\n",
    "            prob = model.pi(state)\n",
    "            m = Categorical(prob)\n",
    "            action_index = m.sample().item()\n",
    "            action = (action_index // (128*128), (action_index % (128*128)) // 128, action_index % 5)  \n",
    "            state_prime, reward, done, _ = env.step(action)\n",
    "            state = state_prime\n",
    "            if done:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions where elements are different:\n",
      "(array([122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,\n",
      "       122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,\n",
      "       122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122,\n",
      "       122, 122, 122, 122, 122, 122, 122, 122, 122, 123, 123, 123, 123,\n",
      "       123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "       123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "       123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n",
      "       123, 123, 123, 123, 123, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "       124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "       124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "       124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n",
      "       124], dtype=int64), array([27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35,\n",
      "       35, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43,\n",
      "       44, 44, 45, 45, 46, 46, 47, 47, 48, 48, 49, 49, 50, 50, 27, 27, 28,\n",
      "       28, 29, 29, 30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36,\n",
      "       37, 37, 38, 38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44, 45,\n",
      "       45, 46, 46, 47, 47, 48, 48, 49, 49, 50, 50, 27, 27, 28, 28, 29, 29,\n",
      "       30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36, 37, 37, 38,\n",
      "       38, 39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 46,\n",
      "       47, 47, 48, 48, 49, 49, 50, 50], dtype=int64), array([0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3,\n",
      "       0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3,\n",
      "       0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3,\n",
      "       0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3,\n",
      "       0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3,\n",
      "       0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3,\n",
      "       0, 3, 0, 3, 0, 3, 0, 3, 0, 3, 0, 3], dtype=int64))\n",
      "Number of differences: 144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mask = tf.not_equal(original, modified)\n",
    "indices = tf.where(mask)\n",
    "\n",
    "# Print the positions where the elements are different\n",
    "print(\"Positions where elements are different:\")\n",
    "print(np.where(mask))\n",
    "\n",
    "num_differences = np.sum(mask)\n",
    "\n",
    "# Print the number of differences\n",
    "print(\"Number of differences:\", num_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference at position [122  27   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  27   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  28   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  28   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  29   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  29   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  30   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  30   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  31   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  31   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  32   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  32   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  33   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  33   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  34   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  34   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  35   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  35   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  36   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  36   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  37   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  37   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  38   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  38   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  39   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  39   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  40   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  40   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  41   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  41   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  42   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  42   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  43   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  43   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  44   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  44   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  45   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  45   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  46   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  46   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  47   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  47   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  48   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  48   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  49   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  49   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [122  50   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [122  50   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  27   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  27   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  28   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  28   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  29   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  29   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  30   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  30   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  31   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  31   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  32   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  32   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  33   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  33   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  34   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  34   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  35   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  35   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  36   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  36   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  37   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  37   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  38   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  38   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  39   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  39   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  40   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  40   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  41   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  41   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  42   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  42   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  43   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  43   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  44   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  44   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  45   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  45   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  46   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  46   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  47   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  47   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  48   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  48   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  49   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  49   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [123  50   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [123  50   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  27   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  27   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  28   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  28   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  29   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  29   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  30   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  30   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  31   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  31   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  32   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  32   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  33   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  33   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  34   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  34   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  35   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  35   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  36   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  36   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  37   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  37   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  38   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  38   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  39   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  39   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  40   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  40   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  41   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  41   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  42   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  42   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  43   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  43   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  44   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  44   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  45   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  45   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  46   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  46   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  47   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  47   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  48   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  48   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  49   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  49   3]: original=[1.], modified=[-1.]\n",
      "Difference at position [124  50   0]: original=[-1.], modified=[1.]\n",
      "Difference at position [124  50   3]: original=[1.], modified=[-1.]\n"
     ]
    }
   ],
   "source": [
    "for idx in indices:\n",
    "    row_idx, col_idx, channel_idx = idx[0], idx[1], idx[2]\n",
    "    original_value = tf.gather_nd(original, [idx])\n",
    "    modified_value = tf.gather_nd(modified, [idx])\n",
    "    print(f\"Difference at position {idx}: original={original_value.numpy()}, modified={modified_value.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for idx in indices:\n",
    "    count += 1\n",
    "\n",
    "    row_idx, col_idx, channel_idx = idx[0], idx[1], idx[2]\n",
    "    original_value = tf.gather_nd(original, [idx])  # Get original value\n",
    "    modified = tf.tensor_scatter_nd_update(\n",
    "        modified, [[row_idx, col_idx, channel_idx]], original_value  # Update modified tensor\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Modified tensor with original values rewritten:\")\n",
    "print(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.gan_processing.DecodingFunctions import DecodingFunctions\n",
    "\n",
    "# functions to move the output from [-1, 1] to [0, 1] range\n",
    "decoding_functions = DecodingFunctions(threshold_callback = lambda: 0.5)\n",
    "decoding_functions.set_rescaling(rescaling = tf.keras.layers.Rescaling)\n",
    "decoding_functions.update_rescale_values(max_value = 1, shift_value = 1)\n",
    "rescale_function = decoding_functions.rescale\n",
    "\n",
    "# function to flatten the gan output to an image with 1 channel\n",
    "decoding_function = decoding_functions.argmax_multilayer_decoding_with_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ref_img, _ = decoding_function(original)\n",
    "# print(gan_outputs_reformatted[i].shape)\n",
    "\n",
    "# save image trough matplotlib\n",
    "plt.imshow(ref_img)\n",
    "plt.savefig('original_level.png')\n",
    "# clear plot\n",
    "plt.clf()\n",
    "\n",
    "ref_img, _ = decoding_function(modified)\n",
    "# print(gan_outputs_reformatted[i].shape)\n",
    "\n",
    "# save image trough matplotlib\n",
    "plt.imshow(ref_img)\n",
    "plt.savefig('modified1_level.png')\n",
    "# clear plot\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.to_img_converter.MultiLayerStackDecoder import MultiLayerStackDecoder\n",
    "from level.LevelVisualizer import LevelVisualizer\n",
    "from level.LevelReader import LevelReader\n",
    "\n",
    "\n",
    "def load_level_decoder():\n",
    "    multilayer_stack_decoder = MultiLayerStackDecoder()\n",
    "    multilayer_stack_decoder.round_to_next_int = True\n",
    "    multilayer_stack_decoder.custom_kernel_scale = True\n",
    "    multilayer_stack_decoder.minus_one_border = False\n",
    "    multilayer_stack_decoder.combine_layers = True\n",
    "    multilayer_stack_decoder.negative_air_value = -1\n",
    "    multilayer_stack_decoder.cutoff_point = 0.5\n",
    "    multilayer_stack_decoder.display_decoding = False\n",
    "    return multilayer_stack_decoder\n",
    "\n",
    "multilayer_stack_decoder = load_level_decoder()\n",
    "level_visualizer = LevelVisualizer()\n",
    "level_reader = LevelReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level Path: created, Blocks: 17 Pigs: 1 Platform: 0 Bird: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "level = multilayer_stack_decoder.decode(modified.numpy())\n",
    "print(\"level\", level)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi = 100)\n",
    "level_visualizer.create_img_of_structure(\n",
    "    level.get_used_elements(), use_grid = False, ax = ax, scaled = True\n",
    ")\n",
    "fig.savefig('modified1_decoded_level.png')\n",
    "plt.clf()\n",
    "\n",
    "# Save level to xml\n",
    "level_xml = level_reader.create_level_from_structure(level.get_used_elements(), red_birds = True, move_to_ground = True)\n",
    "level_reader.write_xml_file(level_xml, os.path.join(\"./\", f'modified_level.xml'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
