{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from data_scripts.LevelDataset import LevelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"train_datasets/test_run_200/test_run_200.tfrecords\"\n",
    "dataset = LevelDataset(dataset_path = dataset_path, batch_size = 1)\n",
    "dataset.load_dataset()\n",
    "iter_data = dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, data in iter_data:\n",
    "    # print(data)\n",
    "    print(image_batch.shape)\n",
    "    print(data.keys())\n",
    "    original = image_batch[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom environment\n",
    "class Environment:\n",
    "    def init(self, map, max_step=math.inf):\n",
    "        self.map = map\n",
    "        self.state = copy.deepcopy(map)\n",
    "        self.step_count = 0\n",
    "        self.max_step = max_step\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = copy.deepcopy(self.map)\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "\n",
    "        state_tensor = torch.tensor(self.state)\n",
    "        return state_tensor\n",
    "\n",
    "    def step(self, action, distance):\n",
    "        # add that pixel to the state (level map)\n",
    "        # action[0] is the x coordinate, action[1] is the y coordinate, action[2] is the type\n",
    "        self.state[action[0], action[1], action[2]] = 1\n",
    "        self.step_count += 1\n",
    "        # reward = self.reward_func(action[0], action[1], action[2], distance)\n",
    "        reward = 0\n",
    "\n",
    "        if self.step_count > self.max_step:\n",
    "            self.done = True\n",
    "\n",
    "        info = {'step': self.step_count, 'action': action, 'reward': reward, 'done': self.done}\n",
    "\n",
    "        return torch.tensor(self.state), torch.tensor(reward), self.done, info\n",
    "    \n",
    "    def reward_func(action, average_pixel):\n",
    "        # get the distance from average of the empty pixels\n",
    "        return 1/(1+math.sqrt((action[0] - average_pixel[0])**2 + (action[1] - average_pixel[1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"train_datasets/modified_test_run_200/modified_test_run_200.tfrecords\"\n",
    "modified_dataset = LevelDataset(dataset_path = dataset_path, batch_size = 1)\n",
    "modified_dataset.load_dataset()\n",
    "modified_iter_data = modified_dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, data in modified_iter_data:\n",
    "    # print(data)\n",
    "    print(image_batch.shape)\n",
    "    modified = image_batch[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src/evaluation')  # Adjust the path as needed\n",
    "\n",
    "from GridSearchDecode import *\n",
    "\n",
    "grid_search_decoder = GridSearchDecode()\n",
    "parameters = grid_search_decoder.create_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Define a custom environment\n",
    "class Environment:\n",
    "    def __init__(self, map, max_step=100):\n",
    "        self.map = map  # Initialize the map\n",
    "        self.state = copy.deepcopy(self.map)\n",
    "        self.step_count = 0\n",
    "        self.max_step = max_step\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = copy.deepcopy(self.map)\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "        state_tensor = torch.tensor(self.state, dtype=torch.float32).flatten()\n",
    "        return state_tensor\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y, z = action  # Decompose the action into coordinates\n",
    "        if self.state[x, y, z] == -1:\n",
    "            self.state[x, y, z] = 1  # Place block if the spot is empty\n",
    "            reward = 10  # Positive reward for placing a block\n",
    "        else:\n",
    "            reward = -10 # Negative reward if block is already there\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.max_step:\n",
    "            self.done = True\n",
    "        return torch.tensor(self.state, dtype=torch.float32).flatten(), reward, self.done, {}\n",
    "\n",
    "# PPO Model\n",
    "class PPO(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PPO, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc_pi = nn.Linear(128, input_size)\n",
    "        self.fc_v = nn.Linear(128, 1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.0003)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.99)\n",
    "        self.data = []  # Initialize data list for storing transitions\n",
    "\n",
    "    def pi(self, x, softmax_dim=0):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc_pi(x)\n",
    "        prob = torch.softmax(x, dim=softmax_dim)\n",
    "        return prob\n",
    "\n",
    "    def v(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "\n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "\n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = zip(*self.data)\n",
    "        self.data = []\n",
    "        return torch.stack(s_lst), torch.tensor(a_lst, dtype=torch.long), torch.tensor(r_lst, dtype=torch.float), torch.stack(s_prime_lst), torch.tensor(done_lst, dtype=torch.float)\n",
    "\n",
    "    def train_net(self, gamma=0.98, lmbda=0.95, eps_clip=0.2):\n",
    "        s, a, r, s_prime, done = self.make_batch()\n",
    "        td_target = r + gamma * self.v(s_prime) * (1 - done)\n",
    "        delta = td_target - self.v(s)\n",
    "        delta = delta.detach().numpy()\n",
    "        advantage_lst = []\n",
    "        advantage = 0.0\n",
    "        for delta_t in delta[::-1]:\n",
    "            advantage = gamma * lmbda * advantage + delta_t[0]\n",
    "            advantage_lst.append([advantage])\n",
    "        advantage_lst.reverse()\n",
    "        advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "        pi = self.pi(s, softmax_dim=1)\n",
    "        pi_a = pi.gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "        ratio = torch.exp(torch.log(pi_a) - torch.log(pi_a.detach()))\n",
    "        surr1 = ratio * advantage\n",
    "        surr2 = torch.clamp(ratio, 1-eps_clip, 1+eps_clip) * advantage\n",
    "        entropy = -(pi * torch.log(pi + 1e-5)).sum(1).mean()\n",
    "        loss = -torch.min(surr1, surr2) + torch.nn.functional.smooth_l1_loss(self.v(s), td_target.detach()) - 0.01 * entropy\n",
    "        self.optimizer.zero_grad()\n",
    "        loss_mean = loss.mean()  # Compute mean loss\n",
    "        loss_mean.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        return loss_mean  # Return the mean loss value\n",
    "\n",
    "def main(modified_iter_data):\n",
    "    model = PPO(128*128*5)  # Initialize the PPO model\n",
    "    score = 0.0\n",
    "    for image_batch, data in modified_iter_data:\n",
    "        \n",
    "        score = 0.0\n",
    "        env = Environment(image_batch[0].numpy())  # Create environment from batch\n",
    "        state = env.reset()  # Reset environment at the start of each batch\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            prob = model.pi(state)  # Policy forward pass\n",
    "            m = Categorical(prob)  # Distribution for sampling actions\n",
    "            action_index = m.sample().item()  # Sample an action\n",
    "            action = (action_index // (128*128), (action_index % (128*128)) // 128, action_index % 5)  # Decode action index to 3D action\n",
    "            state_prime, reward, done, _ = env.step(action)  # Execute action in the environment\n",
    "            model.put_data((state, action_index, reward, state_prime, done))  # Store data for training\n",
    "            state = state_prime\n",
    "            score += reward  # Update score\n",
    "        loss = model.train_net()  # Train model\n",
    "\n",
    "        # if level is stable\n",
    "        if grid_search_decoder.run_evaluation_xml_levels_one_by_one(\"temp\", parameters[0]):\n",
    "            reward += 1000\n",
    "        else:\n",
    "            reward -= 1000\n",
    "\n",
    "        print(f\"Episode Score: {score}, Loss: {loss}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Assume modified_iter_data is your dataset\n",
    "    main(modified_iter_data)\n",
    "    # Save the model\n",
    "    print(\"Model saved successfully\")\n",
    "    torch.save(model.state_dict(), 'ppo_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "print(\"Loading ...\")\n",
    "model = PPO(128*128*5)  # Recreate the model\n",
    "model.load_state_dict(torch.load('ppo_model.pth'))  # Load the saved parameters\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for image_batch, data in modified_iter_data:  # Assuming test data is provided in test_iter_data\n",
    "        state = env.reset()  # Reset the environment\n",
    "        done = False\n",
    "        while not done:\n",
    "            prob = model.pi(state)\n",
    "            m = Categorical(prob)\n",
    "            action_index = m.sample().item()\n",
    "            action = (action_index // (128*128), (action_index % (128*128)) // 128, action_index % 5)  \n",
    "            state_prime, reward, done, _ = env.step(action)\n",
    "            state = state_prime\n",
    "            if done:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mask = tf.not_equal(original, modified)\n",
    "indices = tf.where(mask)\n",
    "\n",
    "# Print the positions where the elements are different\n",
    "print(\"Positions where elements are different:\")\n",
    "print(np.where(mask))\n",
    "\n",
    "num_differences = np.sum(mask)\n",
    "\n",
    "# Print the number of differences\n",
    "print(\"Number of differences:\", num_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in indices:\n",
    "    row_idx, col_idx, channel_idx = idx[0], idx[1], idx[2]\n",
    "    original_value = tf.gather_nd(original, [idx])\n",
    "    modified_value = tf.gather_nd(modified, [idx])\n",
    "    print(f\"Difference at position {idx}: original={original_value.numpy()}, modified={modified_value.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for idx in indices:\n",
    "    count += 1\n",
    "\n",
    "    row_idx, col_idx, channel_idx = idx[0], idx[1], idx[2]\n",
    "    original_value = tf.gather_nd(original, [idx])  # Get original value\n",
    "    modified = tf.tensor_scatter_nd_update(\n",
    "        modified, [[row_idx, col_idx, channel_idx]], original_value  # Update modified tensor\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Modified tensor with original values rewritten:\")\n",
    "print(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.gan_processing.DecodingFunctions import DecodingFunctions\n",
    "\n",
    "# functions to move the output from [-1, 1] to [0, 1] range\n",
    "decoding_functions = DecodingFunctions(threshold_callback = lambda: 0.5)\n",
    "decoding_functions.set_rescaling(rescaling = tf.keras.layers.Rescaling)\n",
    "decoding_functions.update_rescale_values(max_value = 1, shift_value = 1)\n",
    "rescale_function = decoding_functions.rescale\n",
    "\n",
    "# function to flatten the gan output to an image with 1 channel\n",
    "decoding_function = decoding_functions.argmax_multilayer_decoding_with_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ref_img, _ = decoding_function(original)\n",
    "# print(gan_outputs_reformatted[i].shape)\n",
    "\n",
    "# save image trough matplotlib\n",
    "plt.imshow(ref_img)\n",
    "plt.savefig('original_level.png')\n",
    "# clear plot\n",
    "plt.clf()\n",
    "\n",
    "ref_img, _ = decoding_function(modified)\n",
    "# print(gan_outputs_reformatted[i].shape)\n",
    "\n",
    "# save image trough matplotlib\n",
    "plt.imshow(ref_img)\n",
    "plt.savefig('modified1_level.png')\n",
    "# clear plot\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.to_img_converter.MultiLayerStackDecoder import MultiLayerStackDecoder\n",
    "from level.LevelVisualizer import LevelVisualizer\n",
    "from level.LevelReader import LevelReader\n",
    "\n",
    "\n",
    "def load_level_decoder():\n",
    "    multilayer_stack_decoder = MultiLayerStackDecoder()\n",
    "    multilayer_stack_decoder.round_to_next_int = True\n",
    "    multilayer_stack_decoder.custom_kernel_scale = True\n",
    "    multilayer_stack_decoder.minus_one_border = False\n",
    "    multilayer_stack_decoder.combine_layers = True\n",
    "    multilayer_stack_decoder.negative_air_value = -1\n",
    "    multilayer_stack_decoder.cutoff_point = 0.5\n",
    "    multilayer_stack_decoder.display_decoding = False\n",
    "    return multilayer_stack_decoder\n",
    "\n",
    "multilayer_stack_decoder = load_level_decoder()\n",
    "level_visualizer = LevelVisualizer()\n",
    "level_reader = LevelReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "level = multilayer_stack_decoder.decode(modified.numpy())\n",
    "print(\"level\", level)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi = 100)\n",
    "level_visualizer.create_img_of_structure(\n",
    "    level.get_used_elements(), use_grid = False, ax = ax, scaled = True\n",
    ")\n",
    "fig.savefig('modified1_decoded_level.png')\n",
    "plt.clf()\n",
    "\n",
    "# Save level to xml\n",
    "level_xml = level_reader.create_level_from_structure(level.get_used_elements(), red_birds = True, move_to_ground = True)\n",
    "level_reader.write_xml_file(level_xml, os.path.join(\"./\", f'modified_level.xml'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
